# Load packages----
library(tidyverse)
library(readxl)
library(demographr)
library(geographr)

source("R/utils.R")
# Technical notes on the Scottish Index of Multiple Deprivation 2020
# Page 50 https://www.gov.scot/binaries/content/documents/govscot/publications/statistics/2020/09/simd-2020-technical-notes/documents/simd-2020-technical-notes/simd-2020-technical-notes/govscot%3Adocument/SIMD%2B2020%2Btechnical%2Bnotes.pdf

# Data Source: Scottish Index of Multiple Deprivation 2020 https://www.gov.scot/publications/scottish-index-of-multiple-deprivation-2020v2-indicator-data/

tf <- download_file(
  "https://www.gov.scot/binaries/content/documents/govscot/publications/statistics/2020/01/scottish-index-of-multiple-deprivation-2020-indicator-data/documents/simd_2020_indicators/simd_2020_indicators/govscot%3Adocument/SIMD%2B2020v2%2B-%2Bindicators.xlsx",
  "xlxs"
)

raw <- read_excel(tf, sheet = "Data", na = "*")

imd_distances <- raw |>
  select(dz_code = Data_Zone,
         drive_GP,
         drive_primary,
         drive_retail,
         drive_secondary)

#Weighted scale with MFLA----
#Create new function inspired by weighted_domain_scores(): source("https://raw.githubusercontent.com/britishredcrosssociety/covid-19-vulnerability/master/functions.r")

# Steps in weighted_domain_scores() function:
# 1. Scale each indicator to Mean = 0, SD = 1
# 2. Perform either PCA or MLFA and extract weights for that domain 
# 3. Multiply model weights by respective column to get weighted indicators
# 4. Sum weighted indicators
# 5. Rank and quantise into deciles

# Additional Libraries Required
library(broom)

# Create standardised function that scales each indicator to mean = 0 & SD = 1.
standardised = function(x) (x - mean(x))/sd(x)
rank2 = function(x) rank(x, na.last = FALSE)

mfla_score <- function(d) {
  
  # Rank and normalise indicators to mean 0, SD 1.
  d <- d %>%
    mutate_if(is.numeric, list(scaled = function(x) standardised(rank2(x))))
  
  # Extract weights
  d_weights <- d %>%
    select(ends_with("_scaled")) %>%
    factanal(factors = 1) %>%
    tidy() %>%
    select(-uniqueness, weights = fl1) %>%
    mutate(weights = abs(weights),
           weights = weights/sum(weights))
  
  # Multiply model weights by respective column to get weighted indicators
  d_weighted_ind <- d %>%
    select(d_weights$variable) %>%
    map2_dfc(d_weights$weights, `*`) %>%
    select_all(list(~ str_remove(., "_scaled"))) %>%
    select_all(list(~ str_c(., "_weighted")))
  
  # Combine weighted indicators with original data
  d <- bind_cols(d, d_weighted_ind)
  
  # Sum weighted indicators
  d <- d %>%
    mutate(vulnerability_score = reduce(select(., ends_with("_weighted")), `+`))
  
  # Return data
  return(d)
  
}

# Apply the function

distances_mfla <- imd_distances |>
  mfla_score() |>
  select(dz_code,
         vulnerability_score)

# Check if codes are equal
distances_dz <- imd_distances |> 
  distinct(dz_code) |>
  pull()

geographr_codes <- lookup_postcode_oa11_lsoa11_msoa11_ltla20 |>
  select(dz_code = lsoa11_code,
         lad_code = ltla20_code) |>
  filter(str_detect(lad_code, "^S"))

geographr_dz <- geographr_codes |>
  distinct(dz_code) |>
  pull()

if(!(setequal(distances_dz, geographr_dz))) {
  stop("DZS don't match")
} else {
  "LADS match"
}

# Join codes
distances_dz <- left_join(distances_mfla, geographr_codes, by = "dz_code") |>
  relocate(lad_code)

# Add population
pop_dz <- population_dz_20 |>
  filter_codes(dz_code, "^S") |>
  filter(sex == "All") |>
  select(dz_code,
         total_population)

#Calculate extent
distances_lad <- distances_dz |>
  left_join(pop_dz, by = "dz_code") |>
  calculate_extent(
    var = vulnerability_score,
    higher_level_geography = lad_code,
    population = total_population,
    weight_high_scores = TRUE
  ) |>
  rename(distances_extent = extent)

distances_lad <- distances_lad |>
  mutate(rank = rank(distances_extent)) |>
  mutate(deciles = quantise(rank, num_quantiles = 10))

distances_lad |>
  ggplot(aes(y = distances_extent)) +
  geom_boxplot() +
  ylab("Distance to services Extent") +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank())

#Weighted scale with factor analysis----
# Check the correlation between different measures of distances to services
cor(imd_distances[, -1])
library(psych)
psych::alpha(imd_distances[, -1])
describe(imd_distances[, -1], skew = FALSE)

# Standardise indicators
standardised_distances <- imd_distances |>
  mutate_if(is.numeric, scale)

# Create a weighted scale with factor analysis
fa <- factanal(standardised_distances[, -1], 
                factors = 1, scores = "regression") 

standardised_distances$weighted_scale <- fa$scores
loadings(fa)

describe(standardised_distances, skew = FALSE)

