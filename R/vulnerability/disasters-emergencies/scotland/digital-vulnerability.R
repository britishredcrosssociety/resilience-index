# Load packages 
library(tidyverse)
library(demographr)
library(geographr)

source("R/utils.R")

# CACI digital vulnerability data ----
# Provided at the postcode level (for each postcode with more than 6 adults)
# Digital vulnerability is combination of 6 variables:
# fixed internet speed + online purchasing + online finance + mobile phone + internet user + confused by computer

vuln <- read_csv("data/on-disk/vul_zscores.csv")

dig_vuln <- vuln |>
  filter(region == "Scot") |>
  mutate(postcode = gsub(' ','', postcode)) |>
  select(postcode,
  vul_dig_brdbnd, 
  vul_dig_buyonl,
  vul_dig_manca_net,
  vul_dig_mobnon,
  vul_dig_netusr,
  vul_dig_confuse) 

dig_vuln |>
  pivot_longer(vul_dig_brdbnd:vul_dig_confuse, names_to = "variable", values_to = "value") %>%
  ggplot(aes(x = value)) +
  geom_histogram(bins = 30) +
  facet_wrap(vars(variable), ncol = 3, scales = "free",
             labeller = as_labeller(c(vul_dig_brdbnd = "Fixed internet speed",
                                      vul_dig_buyonl = "No online purchasing",
                                      vul_dig_manca_net = "No online finance",
                                      vul_dig_mobnon = "No mobile phone",
                                      vul_dig_netusr = "Not internet users",
                                      vul_dig_confuse = "Confused by computers")))

# Add DZ----
postcode_lookup <- lookup_postcode_oa11_lsoa11_msoa11_ltla20 |>
  filter(str_detect(msoa11_code, "^S")) |>
  select(postcode,
         dz_code = lsoa11_code)

# Check not found in lookup (and vice versa)
nrow(dig_vuln |> anti_join(postcode_lookup, by = "postcode"))
#0
nrow(postcode_lookup |> anti_join(dig_vuln, by = "postcode"))
#98876 - it could be because there are less than 6 adults or they could just be missing

# Missing values----
sum(is.na(dig_vuln))

# Check that the postcodes of missing values are not from the same data zone
na.dig_vuln <- dig_vuln |>
  keep_na() |>
  left_join(postcode_lookup) |>
  relocate(dz_code)

sort(table(na.dig_vuln$dz_code))

na_zone <- na.dig_vuln |>
  group_by(dz_code) |>
  summarise(n_na = n()) |>
  left_join(dig_vuln |>
              left_join(postcode_lookup) |>
              relocate(dz_code) |>
              group_by(dz_code) |>
              summarise(n_tot = n()), by = "dz_code") |>
  mutate(prop = n_na/n_tot) |>
  arrange(desc(prop))

head(na_zone)

# Group by Data Zone----
dig_vuln_dz <- dig_vuln |>
  left_join(postcode_lookup, by = "postcode") |>
  relocate(dz_code) |>
  group_by(dz_code) |>
  summarise_if(is.numeric, mean)

# Check if Data Zones match
dv_dz <-
  dig_vuln_dz |> 
  distinct(dz_code) |>
  pull()

geographr_dz <-
  lookup_postcode_oa11_lsoa11_msoa11_ltla20 |> 
  filter(str_detect(msoa11_code, "^S")) |>
  select(postcode,
         dz_code = lsoa11_code) |>
  distinct(dz_code) |>
  pull()

if(!(setequal(dv_dz, geographr_dz))) {
  stop("DZ don't match")
} else {
  "DZ match"
}

# There are 3 missing data zones
setdiff(geographr_dz, dv_dz) #Petershill 04, Sighthill 02, Sighthill 03

#Create new function inspired by weighted_domain_scores(): source("https://raw.githubusercontent.com/britishredcrosssociety/covid-19-vulnerability/master/functions.r")

# Steps in weighted_domain_scores() function:
# 1. Scale each indicator to Mean = 0, SD = 1
# 2. Perform either PCA or MLFA and extract weights for that domain 
# 3. Multiply model weights by respective column to get weighted indicators
# 4. Sum weighted indicators
# 5. Rank and quantise into deciles

# Additional Libraries Required
library(broom)

# Create standardised function that scales each indicator to mean = 0 & SD = 1.
standardised = function(x) (x - mean(x))/sd(x)
rank2 = function(x) rank(x, na.last = FALSE)

mfla_score <- function(d) {
  
  # Rank and normalise indicators to mean 0, SD 1.
  d <- d %>%
    mutate_if(is.numeric, list(scaled = function(x) standardised(rank2(x))))
  
  # Extract weights
  d_weights <- d %>%
    select(ends_with("_scaled")) %>%
    factanal(factors = 1) %>%
    tidy() %>%
    select(-uniqueness, weights = fl1) %>%
    mutate(weights = abs(weights),
           weights = weights/sum(weights))
  
  # Multiply model weights by respective column to get weighted indicators
  d_weighted_ind <- d %>%
    select(d_weights$variable) %>%
    map2_dfc(d_weights$weights, `*`) %>%
    select_all(list(~ str_remove(., "_scaled"))) %>%
    select_all(list(~ str_c(., "_weighted")))
  
  # Combine weighted indicators with original data
  d <- bind_cols(d, d_weighted_ind)
  
  # Sum weighted indicators
  d <- d %>%
    mutate(vulnerability_score = reduce(select(., ends_with("_weighted")), `+`))

  # Return data
  return(d)
  
}

#Apply the function
dig_vuln_mfla <- dig_vuln_dz |>
  mfla_score() |>
  select(dz_code,
         vulnerability_score)
  
# Add population
pop_dz <- population_dz_20 |>
  filter_codes(dz_code, "^S") |>
  filter(sex == "All") |>
  select(dz_code,
         total_population)

lad_lookup <- lookup_postcode_oa11_lsoa11_msoa11_ltla20 |>
  filter(str_detect(msoa11_code, "^S")) |>
  select(dz_code = lsoa11_code,
         lad_code = ltla20_code)

#Calculate extent
dig_vuln_lad <- dig_vuln_mfla |>
  left_join(lad_lookup, by = "dz_code") |>
  left_join(pop_dz, by = "dz_code") |>
  relocate(dz_code, lad_code) |>
  calculate_extent(
    var = vulnerability_score,
    higher_level_geography = lad_code,
    population = total_population,
    weight_high_scores = T
  ) |>
  rename(dig_vuln_extent = extent)

dig_vuln_lad <- dig_vuln_lad |>
  mutate(rank = rank(dig_vuln_extent)) |>
  mutate(deciles = quantise(rank, num_quantiles = 10))

dig_vuln_lad |>
  ggplot(aes(y = dig_vuln_extent)) +
  geom_boxplot() +
  ylab("Digital Vulnerability Extent") +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank())
